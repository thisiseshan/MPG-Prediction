{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MPG-Prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ46Cbj4Syou",
        "colab_type": "code",
        "outputId": "353829a6-3a1a-4ba4-cd0b-4afacb1cebfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!unzip test2.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  test2.zip\n",
            "   creating: test2/\n",
            "  inflating: __MACOSX/._test2        \n",
            "  inflating: test2/r.json            \n",
            "  inflating: __MACOSX/test2/._r.json  \n",
            "  inflating: test2/linearRegression.py  \n",
            "  inflating: __MACOSX/test2/._linearRegression.py  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNUO4lYcS26d",
        "colab_type": "code",
        "outputId": "ac34b314-f12b-4d97-a84a-2b776592eca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd test2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/test2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF6jcBhySFUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import json\n",
        "x = list()\n",
        "y = list()\n",
        "def f(x):\n",
        "  y = x*randint(0,10)\n",
        "  return y\n",
        "\n",
        "with open('r.json') as myfile:\n",
        "  data=myfile.read()\n",
        "data = json.loads(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JObj09mParlp",
        "colab_type": "code",
        "outputId": "f098f82a-9476-4a58-cda8-75ae2150e839",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x = []\n",
        "y = []\n",
        "for i in range(len(data)):\n",
        "    #car = json.loads(data[i])\n",
        "    car = data[i]\n",
        "    if(car[\"Miles_per_Gallon\"] is'None' or car[\"Miles_per_Gallon\"] is None):\n",
        "        continue\n",
        "    if(car[\"Horsepower\"] is None or car[\"Horsepower\"] is 'null' or car[\"Cylinders\"]  is None or car['Acceleration'] is None or car['Weight_in_lbs'] is None ):\n",
        "        continue\n",
        "    if(car[\"Horsepower\"] != None or car[\"Horsepower\"] != 'null' or car[\"Cylinders\"] !=None or car[\"Cylinders\"] != 'null' or car['Acceleration'] != 'null' or car['Weight_in_lbs'] != 'null' ):\n",
        "        x.append([ car[\"Horsepower\"]])\n",
        "        y.append(car[\"Miles_per_Gallon\"])\n",
        "        \n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\", input_dim=1),\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "  \n",
        "optimizer = tf.keras.optimizers.SGD(lr=8e-6, momentum=0.9)\n",
        "model.compile(loss=\"mse\", optimizer=optimizer, metrics=['accuracy'])\n",
        "  \n",
        "\n",
        "model.fit(np.array(x), np.array(y),\n",
        "          batch_size=int(len(x)*0.9),epochs=100,\n",
        "          )\n",
        "\n",
        "\n",
        "\n",
        "k = list()\n",
        "z = list()\n",
        "\n",
        "\n",
        "for i in range (10):\n",
        "    t = randint(0,len(data))\n",
        "    testData = x[i]\n",
        "    testPredict = model.predict(testData)\n",
        "    k.append(testData)\n",
        "    z.append(testPredict)\n",
        "\n",
        "a = np.array(k)\n",
        "b = np.array(z) \n",
        "\n",
        "a = a.transpose()\n",
        "b = b.T[0]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[130], [165], [150], [150], [140], [198], [220], [215], [225], [190], [170], [160], [150], [225], [95], [95], [97], [85], [88], [46], [87], [90], [95], [113], [90], [215], [200], [210], [193], [88], [90], [95], [100], [105], [100], [88], [100], [165], [175], [153], [150], [180], [170], [175], [110], [72], [100], [88], [86], [90], [70], [76], [65], [69], [60], [70], [95], [80], [54], [90], [86], [165], [175], [150], [153], [150], [208], [155], [160], [190], [97], [150], [130], [140], [150], [112], [76], [87], [69], [86], [92], [97], [80], [88], [175], [150], [145], [137], [150], [198], [150], [158], [150], [215], [225], [175], [105], [100], [100], [88], [95], [46], [150], [167], [170], [180], [100], [88], [72], [94], [90], [85], [107], [90], [145], [230], [49], [75], [91], [112], [150], [110], [122], [180], [95], [100], [100], [67], [80], [65], [75], [100], [110], [105], [140], [150], [150], [140], [150], [83], [67], [78], [52], [61], [75], [75], [75], [97], [93], [67], [95], [105], [72], [72], [170], [145], [150], [148], [110], [105], [110], [95], [110], [110], [129], [75], [83], [100], [78], [96], [71], [97], [97], [70], [90], [95], [88], [98], [115], [53], [86], [81], [92], [79], [83], [140], [150], [120], [152], [100], [105], [81], [90], [52], [60], [70], [53], [100], [78], [110], [95], [71], [70], [75], [72], [102], [150], [88], [108], [120], [180], [145], [130], [150], [68], [80], [58], [96], [70], [145], [110], [145], [130], [110], [105], [100], [98], [180], [170], [190], [149], [78], [88], [75], [89], [63], [83], [67], [78], [97], [110], [110], [48], [66], [52], [70], [60], [110], [140], [139], [105], [95], [85], [88], [100], [90], [105], [85], [110], [120], [145], [165], [139], [140], [68], [95], [97], [75], [95], [105], [85], [97], [103], [125], [115], [133], [71], [68], [115], [85], [88], [90], [110], [130], [129], [138], [135], [155], [142], [125], [150], [71], [65], [80], [80], [77], [125], [71], [90], [70], [70], [65], [69], [90], [115], [115], [90], [76], [60], [70], [65], [90], [88], [90], [90], [78], [90], [75], [92], [75], [65], [105], [65], [48], [48], [67], [67], [67], [67], [62], [132], [100], [88], [72], [84], [84], [92], [110], [84], [58], [64], [60], [67], [65], [62], [68], [63], [65], [65], [74], [75], [75], [100], [74], [80], [76], [116], [120], [110], [105], [88], [85], [88], [88], [88], [85], [84], [90], [92], [74], [68], [68], [63], [70], [88], [75], [70], [67], [67], [67], [110], [85], [92], [112], [96], [84], [90], [86], [52], [84], [79], [82]]\n",
            "[18, 15, 18, 16, 17, 15, 14, 14, 14, 15, 15, 14, 15, 14, 24, 22, 18, 21, 27, 26, 25, 24, 25, 26, 21, 10, 10, 11, 9, 27, 28, 25, 19, 16, 17, 19, 18, 14, 14, 14, 14, 12, 13, 13, 18, 22, 19, 18, 23, 28, 30, 30, 31, 35, 27, 26, 24, 25, 23, 20, 21, 13, 14, 15, 14, 17, 11, 13, 12, 13, 19, 15, 13, 13, 14, 18, 22, 21, 26, 22, 28, 23, 28, 27, 13, 14, 13, 14, 15, 12, 13, 13, 14, 13, 12, 13, 18, 16, 18, 18, 23, 26, 11, 12, 13, 12, 18, 20, 21, 22, 18, 19, 21, 26, 15, 16, 29, 24, 20, 19, 15, 24, 20, 11, 20, 19, 15, 31, 26, 32, 25, 16, 16, 18, 16, 13, 14, 14, 14, 29, 26, 26, 31, 32, 28, 24, 26, 24, 26, 31, 19, 18, 15, 15, 16, 15, 16, 14, 17, 16, 15, 18, 21, 20, 13, 29, 23, 20, 23, 24, 25, 24, 18, 29, 19, 23, 23, 22, 25, 33, 28, 25, 25, 26, 27, 17.5, 16, 15.5, 14.5, 22, 22, 24, 22.5, 29, 24.5, 29, 33, 20, 18, 18.5, 17.5, 29.5, 32, 28, 26.5, 20, 13, 19, 19, 16.5, 16.5, 13, 13, 13, 31.5, 30, 36, 25.5, 33.5, 17.5, 17, 15.5, 15, 17.5, 20.5, 19, 18.5, 16, 15.5, 15.5, 16, 29, 24.5, 26, 25.5, 30.5, 33.5, 30, 30.5, 22, 21.5, 21.5, 43.1, 36.1, 32.8, 39.4, 36.1, 19.9, 19.4, 20.2, 19.2, 20.5, 20.2, 25.1, 20.5, 19.4, 20.6, 20.8, 18.6, 18.1, 19.2, 17.7, 18.1, 17.5, 30, 27.5, 27.2, 30.9, 21.1, 23.2, 23.8, 23.9, 20.3, 17, 21.6, 16.2, 31.5, 29.5, 21.5, 19.8, 22.3, 20.2, 20.6, 17, 17.6, 16.5, 18.2, 16.9, 15.5, 19.2, 18.5, 31.9, 34.1, 35.7, 27.4, 25.4, 23, 27.2, 23.9, 34.2, 34.5, 31.8, 37.3, 28.4, 28.8, 26.8, 33.5, 41.5, 38.1, 32.1, 37.2, 28, 26.4, 24.3, 19.1, 34.3, 29.8, 31.3, 37, 32.2, 46.6, 27.9, 40.8, 44.3, 43.4, 36.4, 30, 44.6, 33.8, 29.8, 32.7, 23.7, 35, 32.4, 27.2, 26.6, 25.8, 23.5, 30, 39.1, 39, 35.1, 32.3, 37, 37.7, 34.1, 34.7, 34.4, 29.9, 33, 33.7, 32.4, 32.9, 31.6, 28.1, 30.7, 25.4, 24.2, 22.4, 26.6, 20.2, 17.6, 28, 27, 34, 31, 29, 27, 24, 36, 37, 31, 38, 36, 36, 36, 34, 38, 32, 38, 25, 38, 26, 22, 32, 36, 27, 27, 44, 32, 28, 31]\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1400.1292 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 459.1714 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 267.3750 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 505.9788 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 319.6823 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 222.6562 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 301.6966 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 302.8689 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 233.8730 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 218.9615 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 253.3757 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 245.4781 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 215.7613 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 228.2245 - accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 243.7000 - accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 233.0958 - accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 216.3282 - accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 217.8635 - accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 222.6069 - accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 217.5437 - accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 1ms/step - loss: 213.9670 - accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 217.0445 - accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 217.8767 - accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 214.7274 - accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.7519 - accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 214.3354 - accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.6171 - accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.7384 - accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.8107 - accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.5462 - accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.2828 - accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.4542 - accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.5979 - accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.4708 - accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.0755 - accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.5202 - accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 214.6311 - accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 214.0525 - accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.8098 - accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.7141 - accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 216.4120 - accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 216.1249 - accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.3762 - accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.4957 - accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 215.8465 - accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 216.8934 - accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 214.4871 - accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.0462 - accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.9329 - accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 214.4275 - accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.8872 - accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.0623 - accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.7913 - accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.3528 - accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.1687 - accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.5576 - accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.4782 - accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.5182 - accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.3902 - accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.9803 - accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.9197 - accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.3794 - accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.3830 - accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.5159 - accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.6649 - accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.4220 - accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.7254 - accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 213.0849 - accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.4731 - accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.0653 - accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.3831 - accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.1347 - accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.1320 - accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.7319 - accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.7248 - accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.2899 - accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 211.9954 - accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 211.9153 - accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 211.8259 - accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 211.8896 - accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 211.9496 - accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.4186 - accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 211.6841 - accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 211.9030 - accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 214.5966 - accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 214.3719 - accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 211.9670 - accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.7996 - accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 215.6285 - accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 215.7245 - accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 212.8937 - accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 211.7816 - accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 211.8598 - accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 211.7789 - accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 211.5975 - accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 211.3720 - accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 211.3006 - accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 211.2917 - accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 211.3085 - accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 211.0942 - accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}